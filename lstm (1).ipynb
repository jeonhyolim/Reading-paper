{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8409b6db",
   "metadata": {},
   "source": [
    "## 참고자료\n",
    "\n",
    "1. https://colab.research.google.com/gist/SauravMaheshkar/168f0817f0cd29dd4048868fb0dd4401/lstms-in-pytorch.ipynb#scrollTo=n1XaWIg0w6XZ\n",
    "2.\n",
    "https://wikidocs.net/60691"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9ef22b",
   "metadata": {},
   "source": [
    "# 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30bc3260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsail/hyolim/hyolim_py38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data\n",
    "from torch.autograd import Variable\n",
    "from torchtext import data, datasets\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d28b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 2e-5\n",
    "batch_size = 32\n",
    "output_size = 2\n",
    "hidden_size = 256\n",
    "embedding_length = 300\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dd50c6",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b350ec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(test_sen=None):\n",
    "    \n",
    "    tokenize = lambda x: x.split()\n",
    "    TEXT = data.Field(sequential=True, tokenize=tokenize, lower=True, include_lengths=True, batch_first=True, fix_length=200)\n",
    "    LABEL = data.LabelField()\n",
    "    train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "    TEXT.build_vocab(train_data, vectors=GloVe(name='6B', dim=300))\n",
    "    LABEL.build_vocab(train_data)\n",
    "\n",
    "    word_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "    train_data, valid_data = train_data.split()\n",
    "    train_iter, valid_iter, test_iter = data.BucketIterator.splits((train_data, valid_data, test_data), \n",
    "                                                                   batch_size=32, \n",
    "                                                                   sort_key=lambda x: len(x.text), \n",
    "                                                                   repeat=False, shuffle=True)\n",
    "\n",
    "    vocab_size = len(TEXT.vocab)\n",
    "\n",
    "    return TEXT, vocab_size, word_embeddings, train_iter, valid_iter, test_iter\n",
    "\n",
    "TEXT, vocab_size, word_embeddings, train_iter, valid_iter, test_iter = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0536a39c",
   "metadata": {},
   "source": [
    "* 필드 정의하기(torchtext.data)\n",
    "    * 앞으로 어떤 전처리를 할 것인지를 정의\n",
    "    * tokenize : 어떤 토큰화 함수를 사용할 것인지 지정. (string.split이 기본값)\n",
    "    * batch_first : 미니 배치 차원을 맨 앞으로 하여 데이터를 불러올 것인지 여부. (False가 기본값), 신경망에 입력되는 텐서의 첫번째 차원 값이 batch_size가 되게 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1912545",
   "metadata": {},
   "source": [
    "- 'TEXT'의 경우, 데이터셋이 순차적인 데이터이므로 sequential=True설정\n",
    "- 'LABEL'의 경우 단순한 클래스를 나타내는 숫자로 순차적 데이터가 아니므로 False로 명시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "879ff90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = lambda x: x.split() # 문장 토큰화 하기\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=tokenize, lower=True, \n",
    "                  include_lengths=True, batch_first=True, fix_length=200)\n",
    "LABEL = data.LabelField(sequential=False, batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc73a5c",
   "metadata": {},
   "source": [
    "# 데이터셋 로드 및 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "352b8945",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dc09b01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['a', 'doctor', 'and', 'a', 'policeman', 'in', 'new', 'orleans', 'have', 'only', '48', 'hours', 'to', 'locate', 'a', 'killer', 'infected', 'with', 'pneumonic', 'plague.<br', '/><br', '/>an', 'effective,', 'and', 'classy,', 'little', 'thriller', 'directed', 'by', 'elia', 'kazan', 'that', 'blends', 'documentary', 'realism', 'with', 'a', 'race', 'against', 'time', 'pulpy', 'heartbeat.', 'set', 'and', 'filmed', 'in', 'and', 'around', 'new', 'orleans,', 'panic', 'in', 'the', 'streets', 'is', 'taken', 'from', 'the', 'story', 'quarantine,', 'some', 'like', \"'em\", 'cold', 'by', 'edna', 'and', 'edward', 'anhalt', 'who', 'won', 'an', 'oscar', 'for', 'original', 'story.', 'it', 'also', 'boasts', 'a', 'fine', 'ensemble', 'cast', 'that', 'deliver', 'top', 'rate', 'performances', 'for', 'their', 'director.', 'in', 'turn,', 'richard', 'widmark', '{bringing', 'the', 'method', 'a', 'year', 'before', 'marlon', 'did', 'for', 'kazan', 'in', 'a', 'streetcar', 'named', 'desire},', 'paul', 'douglas,', 'jack', 'palance', '(as', 'walter', 'jack', 'palance)', '&', 'the', 'wonderfully', 'named', 'zero', 'mostel,', 'all', 'get', 'sweatily', 'moody', 'as', 'the', 'pursuers', 'chase', 'the', 'pursued', 'to', 'halt', 'the', 'onset', 'of', 'a', 'potential', 'black', 'death', 'epidemic.<br', '/><br', '/>where', 'the', 'film', 'scores', 'its', 'main', 'suspense', 'points', 'is', 'with', \"kazan's\", 'astute', 'ability', 'to', 'cut', 'back', 'and', 'forth', 'between', 'the', 'protagonists', 'without', 'altering', 'the', 'flow', 'and', 'mood', 'of', 'the', 'piece.', 'from', \"widmark's\", 'public', 'health', 'doctor,', 'with', 'hypodermic', 'needle', 'in', 'hand,', 'running', 'around', 'trying', 'to', 'locate', 'the', 'bad', 'guys', 'so', 'he', 'can', 'do', 'good;', 'to', 'the', 'bad', 'guys', 'themselves', 'who', 'are', 'bemused', 'as', 'to', 'why', 'there', 'is', 'such', 'a', 'wide', 'scale', 'hunt', 'for', 'them;', 'the', 'tension', 'is', 'stacked', 'up', 'to', 'fever', 'breaking', 'point.', 'to', 'which', 'thankfully', 'the', 'final', 'thirty', 'minutes', 'becomes', 'a', 'cracking', 'piece', 'of', 'cinema.', 'with', 'palance', 'excelling', 'as', 'a', 'nasty', 'villain', 'that', 'ironically', 'puts', 'one', 'in', 'mind', 'of', \"widmark's\", 'own', 'tommy', 'udo', 'from', 'kiss', 'of', 'death', 'three', 'years', 'prior.<br', '/><br', \"/>it's\", 'an', 'imaginative', 'and', 'intelligently', 'written', 'story,', 'one', 'that', 'cunningly', 'links', 'rats', 'and', 'criminals', 'to', 'being', 'carriers', 'of', 'disease.', 'a', 'blight', 'on', 'society', 'as', 'it', 'were.', \"it's\", 'noirish', 'elements,', 'such', 'as', 'paranoia,', 'blend', 'nicely', 'with', 'its', 'basic', 'procedural', 'thriller', 'being.', 'while', 'some', 'memorable', 'scenes', 'are', 'suitably', 'cloaked', 'by', 'the', 'stifling', 'atmosphere', 'that', 'kazan', 'has', 'created.', 'although', 'some', 'of', 'the', 'early', 'character', 'psychologizing', 'threatens', 'to', 'steer', 'the', 'film', 'down', 'some', 'over', 'talky', 'based', 'alleyway,', 'this', 'definitely', 'is', 'a', 'film', 'worth', 'staying', 'with', 'to', 'the', 'end.', 'not', 'essential', 'film-noir,', 'and', 'maybe', 'not', 'even', 'essential', 'kazan,', 'but', 'certainly', 'a', 'highly', 'recommended', 'film', 'that', 'begs', 'to', 'be', 'discovered', 'by', 'a', 'new', 'generation', 'of', 'film', 'lovers', 'and', 'reappraised', 'by', 'the', 'old', 'guard', 'who', 'may', 'have', 'missed', 'it', 'back', 'in', 'the', 'day.', '7.5/10'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bcf44f",
   "metadata": {},
   "source": [
    "- 'text' : []에서 대괄호 안에 위치한 단어들이 첫번째 IMDB 리뷰\n",
    "- 'label' : []에서 대괄호 안의 단어가 첫번째 IMDB 리뷰의 레이블. neg는 부정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19abeed",
   "metadata": {},
   "source": [
    "# 단어집합 만들기\n",
    "* 단어집합: 중복을 제거한 총 단어들의 집합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e970c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, vectors=GloVe(name='6B', dim=300))\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1fe6c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251639"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 집합의 크기: 중복을 제거한 총 단어의 개수\n",
    "vocab_size = len(TEXT.vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "931edaad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([251639, 300])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings = TEXT.vocab.vectors\n",
    "print(word_embeddings.shape)\n",
    "word_embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816466c1",
   "metadata": {},
   "source": [
    "# 데이터 로더 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59b36716",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = train_data.split()\n",
    "train_iter, valid_iter, test_iter = data.BucketIterator.splits((train_data, valid_data, test_data), \n",
    "                                                               batch_size=32, \n",
    "                                                               sort_key=lambda x: len(x.text), \n",
    "                                                               repeat=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "014c77b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 미니 배치의 개수 : 547\n",
      "테스트 데이터의 미니 배치의 개수 : 782\n",
      "검증 데이터의 미니 배치의 개수 : 235\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 미니 배치의 개수 : {}'.format(len(train_iter)))\n",
    "print('테스트 데이터의 미니 배치의 개수 : {}'.format(len(test_iter)))\n",
    "print('검증 데이터의 미니 배치의 개수 : {}'.format(len(valid_iter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3083cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, batch in enumerate(train_iter):\n",
    "    text = batch.text[0]\n",
    "    target = batch.label\n",
    "    target = torch.autograd.Variable(target).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82336dbe",
   "metadata": {},
   "source": [
    "- 배치의 크기 32 * 200\n",
    "- fix_length=200으로 설정했기에, 배치 간 샘플 길이가 200임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c619c47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 200])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb6f8ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        1, 1, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(target.shape)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ac90347",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence=text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fde1d64",
   "metadata": {},
   "source": [
    "# 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7aefcd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\tdef __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length, weights):\n",
    "\t\tsuper(LSTMClassifier, self).__init__()\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.output_size = output_size\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.vocab_size = vocab_size\n",
    "\t\tself.embedding_length = embedding_length\n",
    "\t\t\n",
    "\t\tself.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
    "\t\tself.word_embeddings.weight = nn.Parameter(weights, requires_grad=False) \n",
    "\t\tself.lstm = nn.LSTM(embedding_length, hidden_size) # Our main hero for this tutorial\n",
    "\t\tself.label = nn.Linear(hidden_size, output_size)\n",
    "\t\t\n",
    "\tdef forward(self, input_sentence, batch_size=None):\n",
    "\t\tinput = self.word_embeddings(input_sentence) \n",
    "\t\tinput = input.permute(1, 0, 2) \n",
    "\t\tif batch_size is None:\n",
    "\t\t\th_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda()) \n",
    "\t\t\tc_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda()) \n",
    "\t\telse:\n",
    "\t\t\th_0 = Variable(torch.zeros(1, batch_size, self.hidden_size).cuda())\n",
    "\t\t\tc_0 = Variable(torch.zeros(1, batch_size, self.hidden_size).cuda())\n",
    "\t\toutput, (final_hidden_state, final_cell_state) = self.lstm(input, (h_0, c_0))\n",
    "\t\tfinal_output = self.label(final_hidden_state[-1]) \n",
    "\t\t\n",
    "\t\treturn final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173b081a",
   "metadata": {},
   "source": [
    "def __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length, weights):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82deb116",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = batch_size\n",
    "output_size = output_size\n",
    "hidden_size = hidden_size\n",
    "vocab_size = vocab_size\n",
    "embedding_length = embedding_length\n",
    "word_embeddings = nn.Embedding(vocab_size, embedding_length) # Embedding(251639, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94007ed7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([251639, 300])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights= TEXT.vocab.vectors\n",
    "word_embeddings.weight = nn.Parameter(weights, requires_grad=False) \n",
    "print(word_embeddings.weight.shape)\n",
    "word_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1329c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(embedding_length, hidden_size) # LSTM(300, 256)\n",
    "label = nn.Linear(hidden_size, output_size) # Linear(in_features=256, out_features=2, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd332f7",
   "metadata": {},
   "source": [
    "def forward(self, input_sentence, batch_size=None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "476acf32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 200])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "125e664a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 200, 300])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = word_embeddings(input_sentence) # Embedding(251639, 300)\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e049e99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 28, 300])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = input.permute(1, 0, 2) \n",
    "input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b1df7",
   "metadata": {},
   "source": [
    "Variable 클래스: 각 tensor의 값을 볼 수 있는 data, 미분을 보는 grad, backward를 통한 미분을 계산한 함수 정보인 grad_fn, 총 3개의 함수 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0eecac84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 256])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_0 = Variable(torch.zeros(1, batch_size, hidden_size))\n",
    "print(h_0)\n",
    "h_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "788d1fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 256])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_0 = Variable(torch.zeros(1, batch_size, hidden_size))\n",
    "print(c_0)\n",
    "c_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f0dd689",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (1, 28, 256), got [1, 32, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output, (final_hidden_state, final_cell_state) \u001b[38;5;241m=\u001b[39m \u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "File \u001b[0;32m~/hyolim/hyolim_py38/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/hyolim/hyolim_py38/lib/python3.8/site-packages/torch/nn/modules/rnn.py:579\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    577\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    581\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    582\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m~/hyolim/hyolim_py38/lib/python3.8/site-packages/torch/nn/modules/rnn.py:533\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[1;32m    531\u001b[0m expected_hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[0;32m--> 533\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_hidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExpected hidden[0] size \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m, got \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], expected_hidden_size,\n\u001b[1;32m    536\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/hyolim/hyolim_py38/lib/python3.8/site-packages/torch/nn/modules/rnn.py:196\u001b[0m, in \u001b[0;36mRNNBase.check_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_hidden_size\u001b[39m(\u001b[38;5;28mself\u001b[39m, hx: Tensor, expected_hidden_size: Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    194\u001b[0m                       msg: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m expected_hidden_size:\n\u001b[0;32m--> 196\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(expected_hidden_size, \u001b[38;5;28mlist\u001b[39m(hx\u001b[38;5;241m.\u001b[39msize())))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (1, 28, 256), got [1, 32, 256]"
     ]
    }
   ],
   "source": [
    "output, (final_hidden_state, final_cell_state) = lstm(input, (h_0, c_0))\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b51facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(final_hidden_state, final_cell_state)\n",
    "print(final_hidden_state.shape)\n",
    "print(final_cell_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7aa61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = label(final_hidden_state[-1]) # label: Linear(in_features=256, out_features=2, bias=True)\n",
    "final_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5cdc09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyolim_py38",
   "language": "python",
   "name": "hyolim_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
